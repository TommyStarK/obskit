---
# Source: mimir-distributed/templates/configmap/gateway.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: mimir-distributed-gateway
  namespace: obskit
  labels:
    app.kubernetes.io/name: mimir-distributed
    app.kubernetes.io/instance: mimir
    app.kubernetes.io/component: gateway
data:
  nginx.conf: |
    worker_processes  5;
    error_log  /dev/stderr;
    pid        /tmp/nginx.pid;
    worker_rlimit_nofile 8192;

    events {
      worker_connections  4096;
    }

    http {
      client_body_temp_path /tmp/client_temp;
      proxy_temp_path       /tmp/proxy_temp_path;
      fastcgi_temp_path     /tmp/fastcgi_temp;
      uwsgi_temp_path       /tmp/uwsgi_temp;
      scgi_temp_path        /tmp/scgi_temp;

      default_type application/octet-stream;
      log_format   main '$remote_addr - $remote_user [$time_local]  $status '
            '"$request" $body_bytes_sent "$http_referer" '
            '"$http_user_agent" "$http_x_forwarded_for"';
      access_log   /dev/stderr  main;

      sendfile     on;
      tcp_nopush   on;
      resolver kube-dns.kube-system.svc.cluster.local;

      # Ensure that X-Scope-OrgID is always present, default to the no_auth_tenant for backwards compatibility when multi-tenancy was turned off.
      map $http_x_scope_orgid $ensured_x_scope_orgid {
        default $http_x_scope_orgid;
        "" "anonymous";
      }

      server {
        listen 8080;

        location = / {
          return 200 'OK';
          auth_basic off;
        }

        proxy_set_header X-Scope-OrgID $ensured_x_scope_orgid;

        # Distributor endpoints
        location /distributor {
          proxy_pass      http://mimir-distributed-distributor-headless.obskit.svc.cluster.local:8080$request_uri;
        }
        location = /api/v1/push {
          proxy_pass      http://mimir-distributed-distributor-headless.obskit.svc.cluster.local:8080$request_uri;
        }

        # Alertmanager endpoints
        # location /alertmanager {
        #   proxy_pass      http://mimir-distributed-alertmanager-headless.obskit.svc.cluster.local:8080$request_uri;
        # }
        # location = /multitenant_alertmanager/status {
        #   proxy_pass      http://mimir-distributed-alertmanager-headless.obskit.svc.cluster.local:8080$request_uri;
        # }
        # location = /api/v1/alerts {
        #   proxy_pass      http://mimir-distributed-alertmanager-headless.obskit.svc.cluster.local:8080$request_uri;
        # }

        # Ruler endpoints
        # location /prometheus/config/v1/rules {
        #   proxy_pass      http://mimir-distributed-ruler.obskit.svc.cluster.local:8080$request_uri;
        # }
        # location /prometheus/api/v1/rules {
        #   proxy_pass      http://mimir-distributed-ruler.obskit.svc.cluster.local:8080$request_uri;
        # }

        # location /prometheus/api/v1/alerts {
        #   proxy_pass      http://mimir-distributed-ruler.obskit.svc.cluster.local:8080$request_uri;
        # }
        # location = /ruler/ring {
        #   proxy_pass      http://mimir-distributed-ruler.obskit.svc.cluster.local:8080$request_uri;
        # }

        # Rest of /prometheus goes to the query frontend
        location /prometheus {
          proxy_pass      http://mimir-distributed-query-frontend.obskit.svc.cluster.local:8080$request_uri;
        }

        # Buildinfo endpoint can go to any component
        location = /api/v1/status/buildinfo {
          proxy_pass      http://mimir-distributed-query-frontend.obskit.svc.cluster.local:8080$request_uri;
        }

        # Compactor endpoint for uploading blocks
        location /api/v1/upload/block/ {
          proxy_pass      http://mimir-distributed-compactor.obskit.svc.cluster.local:8080$request_uri;
        }
      }
    }
